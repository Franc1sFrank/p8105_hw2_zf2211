---
title: "p8105_hw2_zf2211"
author: "Francis"
date: "9/30/2018"
output: github_document
---

```{r problem0}
library(tidyverse)
library(tidyr)
```

##Problem1
```{r problem1}
Transit_Data = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada)
```

```{r}
select(Transit_Data, entry) %>% 
mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```
This dataset contains variables like: 
```{r}
names(Transit_Data)
```


I used __janitor::clean_names__ to clean the names of data, then __select__ several variables from the data, at last converted the entry into logical variables.

The number of rows and columns of the resulting dataset is 
```{r}
nrow(Transit_Data)
ncol(Transit_Data)
```

No, it is not yet tidy because route1 to route11 is separated. It will be better to 
sort out together.

1)There are 
```{r}
count(distinct(Transit_Data, station_name, line))
```
stations.

2)There are 
```{r}
count(distinct(filter(Transit_Data, ada == TRUE), station_name, line))
```
stations are ADA compliant.

3)The proportion of station entrance/exits without vending allow entrance is 
```{r}
n_without_vending_allow_entrance = 
  Transit_Data %>% 
  filter(vending == "NO", entry == "YES") %>% 
  count()
n_without_vending = 
  Transit_Data %>% 
  filter(vending == "NO") %>% 
  count()
n_without_vending_allow_entrance / 
  n_without_vending
```

4)There are 
```{r}
reformed_data = Transit_Data %>% 
  gather(key = route_number, value = route_served, route1:route11) %>% 
  filter(route_served != 'NA')
reformed_data %>% 
  filter(route_served == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```
distict stations serve A train.

5)Of the stations that serve the A train, there are
```{r}
reformed_data %>% 
  filter(route_served == "A", ada ==TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```
distinct stations are ADA compliant.

##Problem2
```{r}
library(readxl)
library(tidyverse)
```

```{r problem2}
MrTrash_Wheel = 
  read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 1, range = "A2:N338") %>% 
  janitor::clean_names() %>% 
  filter(dumpster != "NA") %>% 
  mutate(sports_balls = as.integer(sports_balls)) 
```

```{r}
prcp2016 = 
  read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 5, range = "A2:B14") %>% 
  janitor::clean_names() %>%
  filter(!is.na("Total")) %>% 
  mutate(year = 2016)
```

```{r}
prcp2017 = 
  read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 4, range = "A2:B14") %>% 
  janitor::clean_names() %>%
  filter(!is.na("Total")) %>% 
  mutate(year = 2017)
```

Combine datasets
```{r}
prcp = 
  bind_rows(prcp2016, prcp2017) %>%
   mutate(month = month.name[month]) %>% 
    select(year, month, total)
```


The MrTrash_Wheel dataset contains `r nrow(MrTrash_Wheel)` observations and `r ncol(MrTrash_Wheel)` variables, and the prcp dataset contains `r nrow(prcp)` observations and `r ncol(prcp)` variables. We focus on the weight, volumn and different items; total precipitation of each month. The total precipitation in 2017 was `r sum(prcp2017$total)`, and the median number of sports balls in a dumpster in 2016 was `r median(filter(MrTrash_Wheel, year == 2016)$sports_balls)`


```{r problem3}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data(brfss_smart2010, package = "p8105.datasets")
```

```{r}
brfss = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter (topic == "Overall Health") %>% 
  select (-class, -topic, - question, -sample_size, -(confidence_limit_low:geo_location)) %>% 
  spread (key = response, value = data_value ) %>% 
  janitor::clean_names() %>% 
  mutate(Proportion = excellent + very_good)
```
Answers:
There are 
```{r}
nrow(distinct(brfss, locationdesc))
```
unique locations are included in the dataset.
```{r}
nrow(distinct(brfss, locationabbr))
```
states in US are represented. 
```{r} 
count_(brfss, 'locationabbr', sort = TRUE)
```
NJ is the most observed.

```{r}
brfss_2002 = filter(brfss, year == 2002)
median(brfss_2002$excellent, na.rm = TRUE)
```
is the median of the "Excellent" response value.

```{r}
ggplot(brfss_2002, aes(x = excellent)) + geom_histogram()
```

```{r}
brfss_NY = filter(brfss, locationdesc == "NY - New York County")
brfss_Qu = filter(brfss, locationdesc == "NY - Queens County")
brfss_NYQu = rbind(brfss_NY, brfss_Qu)
ggplot(brfss_NYQu, aes(x = year, y = excellent, color = locationdesc)) + geom_point() + geom_smooth(se = FALSE)
```

